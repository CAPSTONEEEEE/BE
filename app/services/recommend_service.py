# app/services/recommend_service.py

from __future__ import annotations
import os
import json
import traceback
from typing import List, Optional, Dict, Any
from dotenv import load_dotenv
from openai import AsyncOpenAI
from fastapi import HTTPException

from sqlalchemy.orm import Session
from sqlalchemy import or_
from app.models.recommend_models import RecommendTourInfo, TourInfoOut

# --- OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
openai_client = None 
try:
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if openai_api_key:
        openai_client = AsyncOpenAI(api_key=openai_api_key)
    else:
        print("OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"Error initializing OpenAI client: {e}")

# =========================================================
# 1. [í•µì‹¬] RAG ê²€ì¦ ë° ì¶”ì²œ ë¡œì§
# =========================================================
async def get_chatbot_search_keywords_and_recommendations(user_message: str, db: Session):
    if not openai_client:
        raise HTTPException(status_code=503, detail="AI ì„œë¹„ìŠ¤ ì—°ê²° ë¶ˆê°€")
    
    # 1. ì…ë ¥ ë°ì´í„° íŒŒì‹±
    try:
        input_data = json.loads(user_message)
        raw_msg = input_data.get("message", user_message)
        # í”„ë¡ íŠ¸ì—ì„œ ë³´ë‚´ì£¼ëŠ” current_profileê³¼ turn_count ë°›ê¸°
        current_profile = input_data.get("current_profile", {})
        turn_count = input_data.get("turn_count", 0)
    except:
        raw_msg = user_message
        current_profile = {}
        turn_count = 0

    # í„´ ì¦ê°€ (ì´ˆê¸°ê°’ ë³´ì •)
    if turn_count == 0:
        # ì²« ì§„ì… ì‹œ ì´ˆê¸°í™”
        current_profile = {
            "style": None,    # ì—¬í–‰ ìŠ¤íƒ€ì¼ (íë§, ì•¡í‹°ë¹„í‹° ë“±)
            "who": None,      # ë™í–‰ (ê°€ì¡±, ì¹œêµ¬, í˜¼ì)
            "when": None,     # ì‹œê¸° (ì´ë²ˆ ì£¼ë§, ê°€ì„ ë“±)
            "transport": None # êµí†µ (ìì°¨, ëšœë²…ì´)
        }
    
    turn_count += 1
    MAX_TURNS = 5  # ìµœëŒ€ ì§ˆë¬¸ íšŸìˆ˜

    print(f"ğŸ”„ Turn: {turn_count}, Input: {raw_msg}")
    print(f"ğŸ“Š Current Profile: {current_profile}")

    try:
        # -----------------------------------------------------
        # Step 1: Router & Interviewer (ì •ë³´ ìˆ˜ì§‘ ë° í‚¤ì›Œë“œ í™•ì¥)
        # -----------------------------------------------------
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ìƒíƒœ ê´€ë¦¬ì ì—­í• 
        system_prompt_router = f"""
        [Role]
        ë‹¹ì‹ ì€ ì†Œë„ì‹œ ì—¬í–‰ ì „ë¬¸ê°€ 'ì†Œì†Œí–‰'ì…ë‹ˆë‹¤. 
        ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë©° [í•„ìˆ˜ ì •ë³´]ë¥¼ ìˆ˜ì§‘í•˜ì—¬ {MAX_TURNS}í„´ ì•ˆì— ìµœì ì˜ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.

        [Target Profile Schema]
        - style: (ì˜ˆ: íë§, ì•¡í‹°ë¹„í‹°, í˜¸ìº‰ìŠ¤, ë§›ì§‘íƒë°©)
        - who: (ì˜ˆ: í˜¼ì, ì—°ì¸, ê°€ì¡±, ì¹œêµ¬)
        - when: (ì˜ˆ: ì´ë²ˆ ì£¼ë§, ì—¬ë¦„ íœ´ê°€, 10ì›”)
        - transport: (ì˜ˆ: ëŒ€ì¤‘êµí†µ, ìì°¨)

        [Current Status]
        - í˜„ì¬ í„´: {turn_count} / {MAX_TURNS}
        - í˜„ì¬ ìˆ˜ì§‘ëœ ì •ë³´: {json.dumps(current_profile, ensure_ascii=False)}

        [Task Rules]
        1. ì‚¬ìš©ìì˜ ì…ë ¥('{raw_msg}')ì„ ë¶„ì„í•˜ì—¬ [Current Status]ì˜ ë¹„ì–´ìˆëŠ”(null) í•„ë“œë¥¼ ì±„ìš°ì‹­ì‹œì˜¤.
        2. ë§Œì•½ 'style'ì´ ëª¨í˜¸í•˜ë‹¤ë©´(ì˜ˆ: "ê·¸ëƒ¥ ì¢‹ì€ ê³³"), êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ 3ê°€ì§€ë¥¼ ì œì•ˆí•˜ì—¬ ì„ íƒí•˜ê²Œ í•˜ì‹­ì‹œì˜¤.
        3. [í•„ìˆ˜ ì •ë³´]ê°€ ëª¨ë‘ ì±„ì›Œì¡Œê±°ë‚˜, í˜„ì¬ í„´ì´ {MAX_TURNS}ì— ë„ë‹¬í–ˆë‹¤ë©´ ì¦‰ì‹œ 'SEARCH_REQ' ìƒíƒœë¡œ ì „í™˜í•˜ì‹­ì‹œì˜¤.
        4. ì•„ì§ ì •ë³´ê°€ ë¶€ì¡±í•˜ë‹¤ë©´ 'QUESTION' ìƒíƒœë¥¼ ìœ ì§€í•˜ê³ , **ë¹„ì–´ìˆëŠ” í•­ëª© ì¤‘ í•˜ë‚˜**ì— ëŒ€í•´ ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸í•˜ì‹­ì‹œì˜¤. (í•œ ë²ˆì— í•˜ë‚˜ë§Œ ì§ˆë¬¸)

        [Output Format (JSON Only)]
        ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤.
        {{
            "status": "QUESTION" | "SEARCH_REQ",
            "updated_profile": {{ ...ì—…ë°ì´íŠ¸ëœ í”„ë¡œí•„... }},
            "next_question": "ì‚¬ìš©ìì—ê²Œ í•  ë‹¤ìŒ ì§ˆë¬¸ (statusê°€ QUESTIONì¼ ë•Œ)",
            "search_keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "ì§€ì—­ëª…(ì„ íƒ)"] (statusê°€ SEARCH_REQì¼ ë•Œ),
            "reasoning": "ì™œ ì´ ìƒíƒœë¥¼ ì„ íƒí–ˆëŠ”ì§€ ì„¤ëª…"
        }}
        """

        response_router = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt_router},
                {"role": "user", "content": raw_msg}
            ],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        
        try:
            router_res = json.loads(response_router.choices[0].message.content)
        except json.JSONDecodeError:
            # AIê°€ JSONì„ ì˜ëª» ë±‰ì—ˆì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
            print("âŒ AI JSON Parsing Error")
            return {
                "ai_response_text": "ì ì‹œ ì‹œìŠ¤í…œ í†µì‹ ì— ë¬¸ì œê°€ ìƒê²¼ìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?",
                "db_recommendations": []
            }

        status = router_res.get("status")
        updated_profile = router_res.get("updated_profile", current_profile)

        # -----------------------------------------------------
        # CASE A: ì•„ì§ ì§ˆë¬¸ì´ ë” í•„ìš”í•¨ (QUESTION)
        # -----------------------------------------------------
        if status == "QUESTION":
            next_q = router_res.get("next_question")
            
            # í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸ìš© ë°ì´í„° íŒ¨í‚¤ì§•
            next_request_data = {
                "next_question": next_q,
                "current_profile": updated_profile,
                "turn_count": turn_count
            }
            
            # ---PROFILE_UPDATE--- ë§ˆì»¤ë¥¼ í¬í•¨í•˜ì—¬ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
            return {
                "ai_response_text": f"{next_q}\n\n---PROFILE_UPDATE---\n{json.dumps(next_request_data, ensure_ascii=False)}\n---END_PROFILE---",
                "db_recommendations": []
            }

        # -----------------------------------------------------
        # CASE B: ê²€ìƒ‰ ìš”ì²­ (SEARCH_REQ)
        # -----------------------------------------------------
        elif status == "SEARCH_REQ":
            keywords = router_res.get("search_keywords", [])
            print(f"ğŸ” AI ì¶”ì¶œ ê²€ìƒ‰ í‚¤ì›Œë“œ: {keywords}")

            # 1. DB ê²€ìƒ‰ (ê²€ì¦)
            found_spots = search_spots_in_db(db, keywords)

            # 2. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° (ìœ ì—°í•œ ëŒ€ì²˜)
            if not found_spots:
                # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´, í‚¤ì›Œë“œë¥¼ ì¡°ê¸ˆ ë” ì¼ë°˜ì ì¸ ê²ƒìœ¼ë¡œ ë°”ê¿”ì„œ ì¬ì§ˆë¬¸ ìœ ë„
                print("âš ï¸ DB ê²€ìƒ‰ ê²°ê³¼ 0ê±´")
                fallback_msg = "ì›í•˜ì‹œëŠ” ì¡°ê±´ì— ë”± ë§ëŠ” ì†Œë„ì‹œ ì •ë³´ë¥¼ ì°¾ê¸°ê°€ ì–´ë µë„¤ìš”. ğŸ˜­\nì¡°ê±´ì„ ì¡°ê¸ˆë§Œ ë„“í˜€ì„œ(ì˜ˆ: 'ì „ë¼ë„ ì „ì²´' ë˜ëŠ” 'ìì—° íë§') ë‹¤ì‹œ ì¶”ì²œí•´ ë“œë¦´ê¹Œìš”?"
                
                # í”„ë¡œí•„ì€ ìœ ì§€í•˜ë˜, í„´ ìˆ˜ëŠ” ìœ ì§€í•˜ê±°ë‚˜ ë¦¬ì…‹
                next_request_data = {
                    "next_question": fallback_msg,
                    "current_profile": updated_profile, 
                    "turn_count": turn_count - 1 # ê¸°íšŒ í•œ ë²ˆ ë” ì¤Œ
                }
                return {
                     "ai_response_text": f"{fallback_msg}\n\n---PROFILE_UPDATE---\n{json.dumps(next_request_data, ensure_ascii=False)}\n---END_PROFILE---",
                    "db_recommendations": []
                }

            # 3. ìµœì¢… ì¶”ì²œ ë©˜íŠ¸ ìƒì„± (ê²€ìƒ‰ëœ ë°ì´í„° ê¸°ë°˜)
            final_response = await generate_final_recommendation(found_spots, updated_profile)
            
            return final_response

    except Exception as e:
        print(f"ğŸ”¥ Critical Error in Recommend Service: {e}")
        traceback.print_exc() # ë¡œê·¸ì— ìƒì„¸ ì—ëŸ¬ ì¶œë ¥
        return {
            "ai_response_text": "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
            "db_recommendations": []
        }

# =========================================================
# Helper: DB ê²€ìƒ‰ í•¨ìˆ˜ (í‚¤ì›Œë“œ ê¸°ë°˜ LIKE ê²€ìƒ‰ + ì†Œë„ì‹œ í•„í„°)
# =========================================================
def search_spots_in_db(db: Session, keywords: List[str]) -> List[TourInfoOut]:
    
    # 1. ì†Œë„ì‹œ ì •ì˜: ëŒ€ë„ì‹œ ì œì™¸
    exclude_cities = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì œì£¼"]
    
    query = db.query(RecommendTourInfo)
    
    # ëŒ€ë„ì‹œ ì œì™¸ í•„í„° ì ìš©
    for city in exclude_cities:
        # addr1ì— 'ì„œìš¸' ë“±ì´ í¬í•¨ë˜ì§€ ì•Šì€ ê³³ë§Œ ì¡°íšŒ
        query = query.filter(RecommendTourInfo.addr1.notlike(f"%{city}%"))

    # 2. í‚¤ì›Œë“œ ê²€ìƒ‰ (OR ì¡°ê±´)
    # keywords ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ê²°ê³¼ì— í¬í•¨
    conditions = []
    for kw in keywords:
        kw = kw.strip()
        if len(kw) < 2: continue # 1ê¸€ì í‚¤ì›Œë“œëŠ” ë¬´ì‹œ (ë„ˆë¬´ ê´‘ë²”ìœ„)
        
        conditions.append(RecommendTourInfo.title.like(f"%{kw}%"))
        conditions.append(RecommendTourInfo.addr1.like(f"%{kw}%"))
        # í•„ìš”í•œ ê²½ìš° cat1, cat2 ë“±ë„ ê²€ìƒ‰
        
    if conditions:
        query = query.filter(or_(*conditions))
    
    # 3. ê²°ê³¼ ì œí•œ (ë„ˆë¬´ ë§ìœ¼ë©´ AI í† í° ì´ˆê³¼)
    # ëœë¤ ì •ë ¬ì„ ì›í•˜ë©´ func.random() ì‚¬ìš© ê°€ëŠ¥ (DB ì¢…ë¥˜ì— ë”°ë¼ ë‹¤ë¦„)
    results = query.limit(5).all()
    
    # Pydantic ëª¨ë¸ë¡œ ë³€í™˜
    return [TourInfoOut.model_validate(item) for item in results]


# =========================================================
# Helper: ìµœì¢… ìƒì„± í•¨ìˆ˜ (Generation)
# =========================================================
async def generate_final_recommendation(spots: List[TourInfoOut], profile: Dict):
    
    # DB ê°ì²´ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™” (AIì—ê²Œ Contextë¡œ ì£¼ê¸° ìœ„í•¨)
    spots_context = json.dumps([s.model_dump() for s in spots], ensure_ascii=False)
    
    system_prompt_final = f"""
    [Role]
    ë‹¹ì‹ ì€ ì†Œë„ì‹œ ì—¬í–‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì‚¬ìš©ì í”„ë¡œí•„: {json.dumps(profile, ensure_ascii=False)}
    
    [Mission]
    ì•„ë˜ [Context Data]ì— ìˆëŠ” ì—¬í–‰ì§€ ì¤‘ 3ê³³ì„ ì„ ì •í•˜ì—¬ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
    
    [Context Data (Real DB Data)]
    {spots_context}

    [Strict Rules]
    1. **ì ˆëŒ€ ì—†ëŠ” ì¥ì†Œë¥¼ ì§€ì–´ë‚´ì§€ ë§ˆì‹­ì‹œì˜¤.** ì˜¤ì§ ìœ„ ë°ì´í„°ì— ìˆëŠ” ê²ƒë§Œ ì¶”ì²œí•˜ì„¸ìš”.
    2. ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ ì•„ë˜ JSON í¬ë§·ì„ ë”°ë¥´ì‹­ì‹œì˜¤.
    
    [Output JSON Format]
    {{
        "final_response_content": "ì—¬ê¸°ì— ì „ì²´ ë‹µë³€ ë‚´ìš©ì„ ì‘ì„±í•˜ì„¸ìš”. \\n\\n ê·œì¹™: \\n 1. ìš”ì•½: ì‚¬ìš©ì ì·¨í–¥({profile.get('style')})ì— ë§ëŠ” ì—¬í–‰ì§€ë¥¼ ê³¨ëë‹¤ëŠ” ë©˜íŠ¸. \\n 2. ì¶”ì²œ ì´ìœ : ê° ì¥ì†Œë¥¼ ì¶”ì²œí•˜ëŠ” ì´ìœ ë¥¼ ê°ì„±ì ìœ¼ë¡œ ì„œìˆ . \\n 3. ë§ˆë¬´ë¦¬: ì¦ê±°ìš´ ì—¬í–‰ ë˜ì‹œë¼ëŠ” ì¸ì‚¬. \\n\\n â€»ëª¨ë“  ë‚´ìš©ì€ ì¤„ê¸€ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ë©°, ë³„ë„ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ì€ ì“°ì§€ ë§ˆì„¸ìš”."
    }}
    """

    response = await openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "system", "content": system_prompt_final}],
        temperature=0.7,
        response_format={"type": "json_object"}
    )
    
    try:
        res_json = json.loads(response.choices[0].message.content)
        final_text = res_json.get("final_response_content", "")
        
        # âš ï¸ í”„ë¡ íŠ¸ì—”ë“œ ì˜¤ë¥˜(undefined) ë°©ì§€ë¥¼ ìœ„í•´ ê°•ì œë¡œ footer ì¶”ê°€
        # í”„ë¡ íŠ¸ íŒŒì„œê°€ \nâ€» ë˜ëŠ” ---RECOMMENDATION--- ë“±ì„ ì°¾ìœ¼ë¯€ë¡œ ë§ì¶°ì¤Œ
        if "â€»" not in final_text:
            final_text += "\n\nâ€» ì¼ë¶€ ì •ë³´ëŠ” ìš´ì˜ ìƒí™©ì— ë”°ë¼ ë³€ë™ë  ìˆ˜ ìˆìœ¼ë‹ˆ ë°©ë¬¸ ì „ ìµœì‹  ì•ˆë‚´ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”."

        return {
            "ai_response_text": final_text, 
            "db_recommendations": spots[:3] # ìƒìœ„ 3ê°œë§Œ í”„ë¡ íŠ¸ë¡œ ì „ë‹¬ (ë²„íŠ¼ í‘œì‹œìš©)
        }
        
    except Exception as e:
        print(f"Final Generation Error: {e}")
        return {
             "ai_response_text": "ì¶”ì²œ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ì—¬í–‰ì§€ ëª©ë¡ì„ ì•„ë˜ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”.",
             "db_recommendations": spots[:3]
        }