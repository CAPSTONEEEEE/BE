# app/services/recommend_service.py

from __future__ import annotations
import os
import json
import traceback
from typing import List, Optional, Dict, Any
from dotenv import load_dotenv
from openai import AsyncOpenAI
from fastapi import HTTPException

from sqlalchemy.orm import Session
from sqlalchemy import or_
from app.models.recommend_models import RecommendTourInfo, TourInfoOut

from math import radians, cos, sin, asin, sqrt

# --- OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
openai_client = None 
try:
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if openai_api_key:
        openai_client = AsyncOpenAI(api_key=openai_api_key)
    else:
        print("OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"Error initializing OpenAI client: {e}")

# =========================================================
# 1. [í•µì‹¬] RAG ê²€ì¦ ë° ì¶”ì²œ ë¡œì§
# =========================================================
async def get_chatbot_search_keywords_and_recommendations(user_message: str, db: Session):
    if not openai_client:
        raise HTTPException(status_code=503, detail="AI ì„œë¹„ìŠ¤ ì—°ê²° ë¶ˆê°€")
    
    # 1. ì…ë ¥ ë°ì´í„° íŒŒì‹±
    try:
        input_data = json.loads(user_message)
        raw_msg = input_data.get("message", user_message)
        # í”„ë¡ íŠ¸ì—ì„œ ë³´ë‚´ì£¼ëŠ” current_profileê³¼ turn_count ë°›ê¸°
        current_profile = input_data.get("current_profile", {})
        turn_count = input_data.get("turn_count", 0)
    except:
        raw_msg = user_message
        current_profile = {}
        turn_count = 0

    # í„´ ì¦ê°€ (ì´ˆê¸°ê°’ ë³´ì •)
    if turn_count == 0:
        # ì²« ì§„ì… ì‹œ ì´ˆê¸°í™”
        current_profile = {
            "style": None,    # ì—¬í–‰ ìŠ¤íƒ€ì¼ (íë§, ì•¡í‹°ë¹„í‹° ë“±)
            "who": None,      # ë™í–‰ (ê°€ì¡±, ì¹œêµ¬, í˜¼ì)
            "when": None,     # ì‹œê¸° (ì´ë²ˆ ì£¼ë§, ê°€ì„ ë“±)
            "transport": None # êµí†µ (ìì°¨, ëšœë²…ì´)
        }
    
    turn_count += 1
    MAX_TURNS = 5  # ìµœëŒ€ ì§ˆë¬¸ íšŸìˆ˜

    print(f"ğŸ”„ Turn: {turn_count}, Input: {raw_msg}")
    print(f"ğŸ“Š Current Profile: {current_profile}")

    try:
        # -----------------------------------------------------
        # Step 1: Router & Interviewer (ì •ë³´ ìˆ˜ì§‘ ë° í‚¤ì›Œë“œ í™•ì¥)
        # -----------------------------------------------------
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ìƒíƒœ ê´€ë¦¬ì ì—­í• 
        system_prompt_router = f"""
        [Role]
        ë‹¹ì‹ ì€ ì†Œë„ì‹œ ì—¬í–‰ ì „ë¬¸ê°€ 'ì†Œì†Œí–‰'ì…ë‹ˆë‹¤. 
        ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë©° [í•„ìˆ˜ ì •ë³´]ë¥¼ ìˆ˜ì§‘í•˜ì—¬ {MAX_TURNS}í„´ ì•ˆì— ìµœì ì˜ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.

        [Target Profile Schema]
        - style: (ì˜ˆ: íë§, ì•¡í‹°ë¹„í‹°, í˜¸ìº‰ìŠ¤, ë§›ì§‘íƒë°©)
        - who: (ì˜ˆ: í˜¼ì, ì—°ì¸, ê°€ì¡±, ì¹œêµ¬)
        - when: (ì˜ˆ: ì´ë²ˆ ì£¼ë§, ì—¬ë¦„ íœ´ê°€, 10ì›”)
        - transport: (ì˜ˆ: ëŒ€ì¤‘êµí†µ, ìì°¨)

        [Current Status]
        - í˜„ì¬ í„´: {turn_count} / {MAX_TURNS}
        - í˜„ì¬ ìˆ˜ì§‘ëœ ì •ë³´: {json.dumps(current_profile, ensure_ascii=False)}

        [Task Rules]
        1. ì‚¬ìš©ìì˜ ì…ë ¥('{raw_msg}')ì„ ë¶„ì„í•˜ì—¬ [Current Status]ì˜ ë¹„ì–´ìˆëŠ”(null) í•„ë“œë¥¼ ì±„ìš°ì‹­ì‹œì˜¤.
        2. ë§Œì•½ 'style'ì´ ëª¨í˜¸í•˜ë‹¤ë©´(ì˜ˆ: "ê·¸ëƒ¥ ì¢‹ì€ ê³³"), êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ 3ê°€ì§€ë¥¼ ì œì•ˆí•˜ì—¬ ì„ íƒí•˜ê²Œ í•˜ì‹­ì‹œì˜¤.
        3. [í•„ìˆ˜ ì •ë³´]ê°€ ëª¨ë‘ ì±„ì›Œì¡Œê±°ë‚˜, í˜„ì¬ í„´ì´ {MAX_TURNS}ì— ë„ë‹¬í–ˆë‹¤ë©´ ì¦‰ì‹œ 'SEARCH_REQ' ìƒíƒœë¡œ ì „í™˜í•˜ì‹­ì‹œì˜¤.
        4. ì•„ì§ ì •ë³´ê°€ ë¶€ì¡±í•˜ë‹¤ë©´ 'QUESTION' ìƒíƒœë¥¼ ìœ ì§€í•˜ê³ , **ë¹„ì–´ìˆëŠ” í•­ëª© ì¤‘ í•˜ë‚˜**ì— ëŒ€í•´ ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸í•˜ì‹­ì‹œì˜¤. (í•œ ë²ˆì— í•˜ë‚˜ë§Œ ì§ˆë¬¸)

        [Output Format (JSON Only)]
        ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤.
        {{
            "status": "QUESTION" | "SEARCH_REQ",
            "updated_profile": {{ ...ì—…ë°ì´íŠ¸ëœ í”„ë¡œí•„... }},
            "next_question": "ì‚¬ìš©ìì—ê²Œ í•  ë‹¤ìŒ ì§ˆë¬¸ (statusê°€ QUESTIONì¼ ë•Œ)",
            "search_keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "ì§€ì—­ëª…(ì„ íƒ)"] (statusê°€ SEARCH_REQì¼ ë•Œ),
            "reasoning": "ì™œ ì´ ìƒíƒœë¥¼ ì„ íƒí–ˆëŠ”ì§€ ì„¤ëª…"
        }}
        """

        response_router = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt_router},
                {"role": "user", "content": raw_msg}
            ],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        
        try:
            router_res = json.loads(response_router.choices[0].message.content)
        except json.JSONDecodeError:
            # AIê°€ JSONì„ ì˜ëª» ë±‰ì—ˆì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
            print("âŒ AI JSON Parsing Error")
            return {
                "ai_response_text": "ì ì‹œ ì‹œìŠ¤í…œ í†µì‹ ì— ë¬¸ì œê°€ ìƒê²¼ìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?",
                "db_recommendations": []
            }

        status = router_res.get("status")
        updated_profile = router_res.get("updated_profile", current_profile)

        # -----------------------------------------------------
        # CASE A: ì•„ì§ ì§ˆë¬¸ì´ ë” í•„ìš”í•¨ (QUESTION)
        # -----------------------------------------------------
        if status == "QUESTION":
            next_q = router_res.get("next_question")
            
            # í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸ìš© ë°ì´í„° íŒ¨í‚¤ì§•
            next_request_data = {
                "next_question": next_q,
                "current_profile": updated_profile,
                "turn_count": turn_count
            }
            
            # ---PROFILE_UPDATE--- ë§ˆì»¤ë¥¼ í¬í•¨í•˜ì—¬ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
            return {
                "ai_response_text": f"{next_q}\n\n---PROFILE_UPDATE---\n{json.dumps(next_request_data, ensure_ascii=False)}\n---END_PROFILE---",
                "db_recommendations": []
            }

        # -----------------------------------------------------
        # CASE B: ê²€ìƒ‰ ìš”ì²­ (SEARCH_REQ)
        # -----------------------------------------------------
        elif status == "SEARCH_REQ":
            keywords = router_res.get("search_keywords", [])
            print(f"ğŸ” AI ì¶”ì¶œ ê²€ìƒ‰ í‚¤ì›Œë“œ: {keywords}")

            # 1. DB ê²€ìƒ‰ (ê²€ì¦)
            found_spots = search_spots_in_db(db, keywords)

            # 2. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° (ìœ ì—°í•œ ëŒ€ì²˜)
            if not found_spots:
                # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´, í‚¤ì›Œë“œë¥¼ ì¡°ê¸ˆ ë” ì¼ë°˜ì ì¸ ê²ƒìœ¼ë¡œ ë°”ê¿”ì„œ ì¬ì§ˆë¬¸ ìœ ë„
                print("âš ï¸ DB ê²€ìƒ‰ ê²°ê³¼ 0ê±´")
                fallback_msg = "ì›í•˜ì‹œëŠ” ì¡°ê±´ì— ë”± ë§ëŠ” ì†Œë„ì‹œ ì •ë³´ë¥¼ ì°¾ê¸°ê°€ ì–´ë µë„¤ìš”. ğŸ˜­\nì¡°ê±´ì„ ì¡°ê¸ˆë§Œ ë„“í˜€ì„œ(ì˜ˆ: 'ì „ë¼ë„ ì „ì²´' ë˜ëŠ” 'ìì—° íë§') ë‹¤ì‹œ ì¶”ì²œí•´ ë“œë¦´ê¹Œìš”?"
                
                # í”„ë¡œí•„ì€ ìœ ì§€í•˜ë˜, í„´ ìˆ˜ëŠ” ìœ ì§€í•˜ê±°ë‚˜ ë¦¬ì…‹
                next_request_data = {
                    "next_question": fallback_msg,
                    "current_profile": updated_profile, 
                    "turn_count": turn_count - 1
                }
                return {
                     "ai_response_text": f"{fallback_msg}\n\n---PROFILE_UPDATE---\n{json.dumps(next_request_data, ensure_ascii=False)}\n---END_PROFILE---",
                    "db_recommendations": []
                }

            # 3. ìµœì¢… ì¶”ì²œ ë©˜íŠ¸ ìƒì„± (ê²€ìƒ‰ëœ ë°ì´í„° ê¸°ë°˜)
            final_response = await generate_final_recommendation(found_spots, updated_profile)
            return final_response

    except Exception as e:
        print(f"ğŸ”¥ Critical Error in Recommend Service: {e}")
        traceback.print_exc() # ë¡œê·¸ì— ìƒì„¸ ì—ëŸ¬ ì¶œë ¥
        return {
            "ai_response_text": "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
            "db_recommendations": []
        }

# =========================================================
# Helper: DB ê²€ìƒ‰ í•¨ìˆ˜ (í‚¤ì›Œë“œ ê¸°ë°˜ LIKE ê²€ìƒ‰ + ì†Œë„ì‹œ í•„í„°)
# =========================================================
def search_spots_in_db(db: Session, keywords: List[str]) -> List[TourInfoOut]:
    
    # 1. ì†Œë„ì‹œ ì •ì˜: ëŒ€ë„ì‹œ ì œì™¸
    exclude_cities = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì œì£¼"]
    
    query = db.query(RecommendTourInfo)
    
    query = query.filter(RecommendTourInfo.addr1.isnot(None))
    query = query.filter(RecommendTourInfo.addr1 != "")
    
    # ëŒ€ë„ì‹œ ì œì™¸ í•„í„° ì ìš©
    for city in exclude_cities:
        query = query.filter(RecommendTourInfo.addr1.notlike(f"%{city}%"))

    # 2. í‚¤ì›Œë“œ ê²€ìƒ‰ (OR ì¡°ê±´)
    # keywords ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ê²°ê³¼ì— í¬í•¨
    conditions = []
    for kw in keywords:
        kw = kw.strip()
        if len(kw) < 2: continue # 1ê¸€ì í‚¤ì›Œë“œëŠ” ë¬´ì‹œ (ë„ˆë¬´ ê´‘ë²”ìœ„)
        
        conditions.append(RecommendTourInfo.title.like(f"%{kw}%"))
        conditions.append(RecommendTourInfo.addr1.like(f"%{kw}%"))
        # í•„ìš”í•œ ê²½ìš° cat1, cat2 ë“±ë„ ê²€ìƒ‰
        
    if conditions:
        query = query.filter(or_(*conditions))
    
    # 3. ê²°ê³¼ ì œí•œ (ë„ˆë¬´ ë§ìœ¼ë©´ AI í† í° ì´ˆê³¼)
    # ëœë¤ ì •ë ¬ì„ ì›í•˜ë©´ func.random() ì‚¬ìš© ê°€ëŠ¥ (DB ì¢…ë¥˜ì— ë”°ë¼ ë‹¤ë¦„)
    results = query.limit(3).all()
    
    # Pydantic ëª¨ë¸ë¡œ ë³€í™˜
    return [TourInfoOut.model_validate(item) for item in results]


# =========================================================
# Helper: ìµœì¢… ìƒì„± í•¨ìˆ˜ (Generation)
# =========================================================
async def generate_final_recommendation(spots: List[TourInfoOut], profile: Dict):
    
    # DB ê°ì²´ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™” (AIì—ê²Œ Contextë¡œ ì£¼ê¸° ìœ„í•¨)
    spots_context = json.dumps([s.model_dump() for s in spots], ensure_ascii=False)
    
    system_prompt_final = f"""
    [Role]
    ë‹¹ì‹ ì€ ì†Œë„ì‹œ ì—¬í–‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ì í”„ë¡œí•„({profile})ì„ ê³ ë ¤í•˜ì—¬ ì¶”ì²œ ë©˜íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
    
    [Context Data]
    {spots_context}

    [Mission]
    ìœ„ [Context Data]ì˜ 3ê°œ ì—¬í–‰ì§€ì— ëŒ€í•´ ê°ê° ë§ì¶¤í˜• ì¶”ì²œ ì´ìœ ë¥¼ ì‘ì„±í•˜ê³ , ì „ì²´ì ì¸ ì†Œê°œë§ì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

    [Output Format (JSON Only)]
    ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ì„ ì¤€ìˆ˜í•˜ì‹­ì‹œì˜¤.
    {{
        "intro_message": "ì‚¬ìš©ìë‹˜, {profile.get('style')} ìŠ¤íƒ€ì¼ì„ ê³ ë ¤í•˜ì—¬ ~í•œ ê³³ë“¤ì„ ì„ ì •í–ˆìŠµë‹ˆë‹¤. (ì „ì²´ ìš”ì•½ 1~2ë¬¸ì¥)",
        "recommendations_detail": [
            {{
                "contentid": "ì—¬í–‰ì§€ ID (Context Dataì™€ ë™ì¼í•´ì•¼ í•¨)",
                "ai_summary": "ì´ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œí•˜ëŠ” êµ¬ì²´ì ì¸ ì´ìœ ì™€ ë§¤ë ¥ í¬ì¸íŠ¸ (3~4ë¬¸ì¥)"
            }},
        ]
    }}
    """

    try:
        response = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "system", "content": system_prompt_final}],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        
        res_json = json.loads(response.choices[0].message.content)
        intro_text = res_json.get("intro_message", "ì¶”ì²œ ì—¬í–‰ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        ai_details = res_json.get("recommendations_detail", [])
        
        final_recommendations = []
        
        for spot in spots:
            # 1. Pydantic ëª¨ë¸ì„ dictë¡œ ë³€í™˜
            spot_dict = spot.model_dump()
            
            # 2. AI ê²°ê³¼ ë§¤ì¹­
            matching_detail = next(
                (item for item in ai_details if str(item.get("contentid")) == str(spot.contentid)), 
                None
            )
            
            # 3. ai_summary í•„ë“œ ì£¼ì…
            if matching_detail and matching_detail.get("ai_summary"):
                spot_dict["ai_summary"] = matching_detail.get("ai_summary")
            else:
                spot_dict["ai_summary"] = spot.addr1 # ì‹¤íŒ¨ ì‹œ ì£¼ì†Œ ì‚¬ìš©

            final_recommendations.append(TourInfoOut(**spot_dict))

        return {
            "ai_response_text": intro_text,
            "db_recommendations": final_recommendations # ì´ì œ ì˜¬ë°”ë¥¸ ê°ì²´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        }
        
    except Exception as e:
        print(f"Generation Error: {e}")
        traceback.print_exc() # ì„œë²„ ë¡œê·¸ì— ì—ëŸ¬ ì›ì¸ ì¶œë ¥
        return {
             "ai_response_text": "ì¶”ì²œ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
             "db_recommendations": spots # ê¸°ë³¸ ë°ì´í„°ë¼ë„ ë°˜í™˜
        }
        
# =========================================================
# ì—¬í–‰ì§€ ìƒì„¸ì •ë³´ ê´€ë ¨
# =========================================================     
def haversine(lon1, lat1, lon2, lat2):
    """
    ë‘ ì§€ì (ìœ„ë„/ê²½ë„) ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚° (ë‹¨ìœ„: km)
    """
    if lon1 is None or lat1 is None or lon2 is None or lat2 is None:
        return 99999 # ê±°ë¦¬ ê³„ì‚° ë¶ˆê°€ ì‹œ í° ê°’ ë°˜í™˜

    # 10ì§„ìˆ˜ -> ë¼ë””ì•ˆ ë³€í™˜
    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])

    # Haversine ê³µì‹
    dlon = lon2 - lon1 
    dlat = lat2 - lat1 
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * asin(sqrt(a)) 
    r = 6371 # ì§€êµ¬ ë°˜ì§€ë¦„ (km)
    return c * r

def get_nearby_spots(contentid: str, db: Session, limit_km: float = 20.0) -> Dict[str, Any]:
    """
    íŠ¹ì • contentidì˜ ì¢Œí‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°˜ê²½ 20km ì´ë‚´ì˜ ì—¬í–‰ì§€ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    # 1. ê¸°ì¤€ì´ ë˜ëŠ” ì—¬í–‰ì§€ ì •ë³´ ì¡°íšŒ (ì´ê²Œ ì‹¤íŒ¨í•˜ë©´ 404ê°€ ëœ¹ë‹ˆë‹¤)
    target_spot = db.query(RecommendTourInfo).filter(RecommendTourInfo.contentid == contentid).first()
    
    if not target_spot:
        print(f"âŒ Error: Content ID {contentid} not found in DB.") # [ë””ë²„ê¹… ë¡œê·¸]
        return {"target": None, "nearby_spots": []}

    # ì¢Œí‘œê°€ ì—†ëŠ” ê²½ìš°(ë°ì´í„° ëˆ„ë½) ì˜ˆì™¸ ì²˜ë¦¬
    if target_spot.mapx is None or target_spot.mapy is None:
        return {"target": TourInfoOut.model_validate(target_spot), "nearby_spots": []}

    target_x = target_spot.mapx # ê²½ë„
    target_y = target_spot.mapy # ìœ„ë„

    # 2. ì „ì²´ ì—¬í–‰ì§€ ì¡°íšŒ (ìì‹  ì œì™¸, ì¢Œí‘œ ìˆëŠ” ê²ƒë§Œ)
    all_spots = db.query(RecommendTourInfo).filter(
        RecommendTourInfo.contentid != contentid, 
        RecommendTourInfo.mapx.isnot(None),
        RecommendTourInfo.mapy.isnot(None)
    ).all()

    nearby_list = []
    
    # 3. ê±°ë¦¬ ê³„ì‚° (Haversine ê³µì‹)
    for spot in all_spots:
        try:
            dist = haversine(target_x, target_y, spot.mapx, spot.mapy)
            if dist <= limit_km:
                spot_data = TourInfoOut.model_validate(spot).model_dump()
                spot_data['distance'] = round(dist, 2) # ê±°ë¦¬(km) ì†Œìˆ˜ì  2ìë¦¬
                nearby_list.append(spot_data)
        except Exception:
            continue # ê³„ì‚° ì—ëŸ¬ ì‹œ ê±´ë„ˆëœ€
    
    # 4. ê±°ë¦¬ìˆœ ì •ë ¬ (ê°€ê¹Œìš´ ìˆœ)
    nearby_list.sort(key=lambda x: x['distance'])

    return {
        "target": TourInfoOut.model_validate(target_spot),
        "nearby_spots": nearby_list
    }

# ìµœì¢… ìƒì„¸ ì •ë³´ ì¡°íšŒ (í˜ì´ì§€ 2ìš©)
def get_spot_detail(contentid: str, db: Session):
    spot = db.query(RecommendTourInfo).filter(RecommendTourInfo.contentid == contentid).first()
    if not spot:
        return None
    return TourInfoOut.model_validate(spot)